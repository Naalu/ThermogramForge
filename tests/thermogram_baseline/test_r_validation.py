"""Tests that validate SplineFitter against R's smooth.spline output.

This module uses reference data generated by R's smooth.spline function
to validate that our Python SplineFitter produces equivalent results.
"""

import os
from pathlib import Path
from typing import Any, Dict, Optional

import numpy as np
import plotly.graph_objects as go  # type: ignore
import polars as pl
import pytest

from thermogram_baseline.spline_fitter import SplineFitter

# Path to R reference data directory
R_REFERENCE_DIR = Path("tests/data/r_reference")


def load_reference_data(pattern: str, size: str = "standard") -> Dict[str, Any]:
    """Load R reference data for a specific pattern and size.

    Args:
        pattern: The pattern name to load (e.g., 'sine', 'exponential')
        size: The dataset size to load (e.g., 'standard', 'small')

    Returns:
        Dictionary containing the x, y values, R fitted values, and R parameters

    Raises:
        pytest.skip: If reference data files are not found
    """
    input_file = R_REFERENCE_DIR / f"{size}_{pattern}_input.csv"
    fitted_file = R_REFERENCE_DIR / f"{size}_{pattern}_fitted.csv"
    params_file = R_REFERENCE_DIR / f"{size}_{pattern}_params.csv"

    if not input_file.exists() or not fitted_file.exists() or not params_file.exists():
        pytest.skip(f"Reference data files not found for {pattern} ({size})")

    input_data = pl.read_csv(input_file)
    fitted_data = pl.read_csv(fitted_file)
    params_data = pl.read_csv(params_file)

    return {
        "x": input_data["x"].to_numpy(),
        "y": input_data["y"].to_numpy(),
        "r_fitted": fitted_data["fitted"].to_numpy(),
        "r_params": {
            "spar": params_data["spar"][0],
            "df": params_data["df"][0],
            "lambda": params_data["lambda"][0],
        },
    }


def compare_fits(
    x: np.ndarray,
    y: np.ndarray,
    r_fitted: np.ndarray,
    pattern: str,
    size: str = "standard",
    r_spar: Optional[float] = None,
    save_plot: bool = True,
) -> Dict[str, Any]:
    """Compare Python SplineFitter with R smooth.spline fitted values.

    Args:
        x: X-coordinates of the data points
        y: Y-coordinates of the data points
        r_fitted: Fitted values from R's smooth.spline
        pattern: The pattern name being tested
        size: Size of the dataset ('standard', 'small')
        r_spar: The smoothing parameter used in R (if available)
        save_plot: Whether to save comparison plots

    Returns:
        Dictionary containing comparison metrics between R and Python fits
    """
    # Create output directory if saving plots
    if save_plot:
        os.makedirs("tests/plots", exist_ok=True)

    # Fit with Python implementation
    fitter = SplineFitter()

    # Try both with and without explicit spar
    if r_spar is not None:
        # Direct spar mapping approach
        spline_direct = fitter.fit_with_gcv(x, y, spar=r_spar)
        py_fitted_direct = spline_direct(x)

        # Also try GCV for comparison
        spline_gcv = fitter.fit_with_gcv(x, y)
        py_fitted_gcv = spline_gcv(x)

        # Use the direct mapping for comparison
        py_fitted = py_fitted_direct
        spline = spline_direct
    else:
        # GCV-only approach
        spline = fitter.fit_with_gcv(x, y)
        py_fitted = spline(x)
        py_fitted_direct = py_fitted
        py_fitted_gcv = py_fitted

    # Calculate differences
    abs_diff = np.abs(py_fitted - r_fitted)
    max_abs_diff = np.max(abs_diff)
    mean_abs_diff = np.mean(abs_diff)

    # Calculate relative differences (avoid division by zero)
    mask = np.abs(r_fitted) > 1e-6
    rel_diff = np.zeros_like(r_fitted)
    rel_diff[mask] = abs_diff[mask] / np.abs(r_fitted[mask])
    max_rel_diff = np.max(rel_diff) * 100  # as percentage
    mean_rel_diff = np.mean(rel_diff) * 100  # as percentage

    # Create comparison plot if requested
    if save_plot:
        fig = go.Figure()

        # Plot raw data
        fig.add_trace(
            go.Scatter(
                x=x, y=y, mode="markers", name="Data", marker=dict(size=5, opacity=0.5)
            )
        )

        # Plot R fit
        fig.add_trace(
            go.Scatter(
                x=x,
                y=r_fitted,
                mode="lines",
                name="R smooth.spline",
                line=dict(color="red", width=2),
            )
        )

        # Plot Python fits
        if r_spar is not None:
            # Plot both direct and GCV fits
            fig.add_trace(
                go.Scatter(
                    x=x,
                    y=py_fitted_direct,
                    mode="lines",
                    name=f"Python (spar={r_spar:.4f})",
                    line=dict(color="green", width=1.5, dash="dash"),
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=x,
                    y=py_fitted_gcv,
                    mode="lines",
                    name=f"Python (GCV, spar~{spline_gcv.spar_approx:.4f})",
                    line=dict(color="blue", width=1.5, dash="dot"),
                )
            )
        else:
            # Just plot GCV fit
            fig.add_trace(
                go.Scatter(
                    x=x,
                    y=py_fitted,
                    mode="lines",
                    name="Python SplineFitter",
                    line=dict(color="green", width=1.5, dash="dash"),
                )
            )

        # Add title with comparison metrics
        if hasattr(spline, "spar_approx"):
            python_spar_str = f"{spline.spar_approx}"
        else:
            python_spar_str = "unknown"

        fig.update_layout(
            title=f"Comparison for {pattern} ({size})<br>"
            f"Max Diff: {max_abs_diff:.6f}, Mean Rel Diff: {mean_rel_diff:.4f}%<br>"
            f"R spar: {r_spar if r_spar is not None else 'unknown'}, "
            f"Python est. spar: {python_spar_str}",
            xaxis_title="X",
            yaxis_title="Y",
            legend=dict(x=0.01, y=0.99),
            width=900,
            height=600,
        )

        # Add grid
        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor="rgba(0,0,0,0.1)")
        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor="rgba(0,0,0,0.1)")

        # Save plot
        fig.write_image(f"tests/plots/validation_{pattern}_{size}.png")

    return {
        "max_absolute_difference": max_abs_diff,
        "mean_absolute_difference": mean_abs_diff,
        "max_relative_difference_percent": max_rel_diff,
        "mean_relative_difference_percent": mean_rel_diff,
        "r_spar": r_spar,
        "python_spar": getattr(spline, "spar_approx", None),
    }


@pytest.mark.parametrize("pattern", ["sine", "exponential", "peaks", "flat", "noisy"])
def test_standard_fit(pattern: str) -> None:
    """Test SplineFitter against R reference data with standard size (n=100).

    Args:
        pattern: The pattern name to test
    """
    # Skip test if reference data doesn't exist (allows running tests without R data)
    if not (R_REFERENCE_DIR / f"standard_{pattern}_input.csv").exists():
        pytest.skip(f"Reference data not found for {pattern}")

    # Load reference data
    ref_data = load_reference_data(pattern, "standard")

    # Get R's spar value
    r_spar = ref_data["r_params"]["spar"]

    # Compare fits - extract arrays from the typed dictionary
    result = compare_fits(
        x=ref_data["x"],
        y=ref_data["y"],
        r_fitted=ref_data["r_fitted"],
        pattern=pattern,
        size="standard",
        r_spar=r_spar,
    )

    # Print results for debugging
    print(f"\nValidation results for {pattern}:")
    for key, value in result.items():
        print(f"  {key}: {value}")

    # Check acceptance criteria - typically <1% difference is acceptable
    # Looser criteria for very noisy data
    if pattern == "noisy":
        assert result["max_relative_difference_percent"] < 15.0
        assert result["mean_relative_difference_percent"] < 6.0
    else:
        assert result["max_relative_difference_percent"] < 10.0
        assert result["mean_relative_difference_percent"] < 2.0


@pytest.mark.parametrize("pattern", ["sine", "peaks"])
def test_small_dataset_fit(pattern: str) -> None:
    """Test SplineFitter against R reference data with small dataset (n=20).

    Args:
        pattern: The pattern name to test
    """
    # Skip test if reference data doesn't exist
    if not (R_REFERENCE_DIR / f"small_{pattern}_input.csv").exists():
        pytest.skip(f"Small reference data not found for {pattern}")

    # Load reference data
    ref_data = load_reference_data(pattern, "small")

    # Get R's spar value
    r_spar = ref_data["r_params"]["spar"]

    # Compare fits
    result = compare_fits(
        ref_data["x"],
        ref_data["y"],
        ref_data["r_fitted"],
        pattern,
        "small",
        r_spar=r_spar,
    )

    # Print results for debugging
    print(f"\nValidation results for small {pattern}:")
    for key, value in result.items():
        print(f"  {key}: {value}")

    # Small datasets may have larger differences
    assert result["max_relative_difference_percent"] < 20.0
    assert result["mean_relative_difference_percent"] < 5.0


def test_thermogram_data() -> None:
    """Test SplineFitter against R reference data with thermogram-like data."""
    # Load thermogram reference data
    thermo_file = R_REFERENCE_DIR / "thermogram_fits.csv"
    params_file = R_REFERENCE_DIR / "thermogram_params.csv"

    if not thermo_file.exists() or not params_file.exists():
        pytest.skip("Thermogram reference data not found")

    thermo_data = pl.read_csv(thermo_file)
    params_data = pl.read_csv(params_file)

    # Extract data
    x = thermo_data["x"].to_numpy()
    y = thermo_data["y"].to_numpy()
    r_fitted_cv = thermo_data["fitted_cv_true"].to_numpy()

    # Get R's spar value (for CV=TRUE)
    r_spar = params_data.filter(pl.col("cv") == "TRUE")["spar"][0]

    # Compare fits
    result = compare_fits(
        x, y, r_fitted_cv, "thermogram", save_plot=True, r_spar=r_spar
    )

    # Print results for debugging
    print("\nValidation results for thermogram data:")
    for key, value in result.items():
        print(f"  {key}: {value}")

    # Check acceptance criteria - should be relatively close
    assert result["max_relative_difference_percent"] < 15.0
    assert result["mean_relative_difference_percent"] < 3.0


if __name__ == "__main__":
    # This allows running the tests individually with visualization
    pattern = "peaks"  # Change to test different patterns

    ref_data = load_reference_data(pattern, "standard")
    r_spar = ref_data["r_params"]["spar"]

    result = compare_fits(
        ref_data["x"],
        ref_data["y"],
        ref_data["r_fitted"],
        pattern,
        "standard",
        r_spar=r_spar,
        save_plot=True,
    )

    print(f"\nValidation results for {pattern}:")
    for key, value in result.items():
        print(f"  {key}: {value}")
